# Redes Nauronales Recurrentes ELMAN y Jordan

Las redes neuronales son modelos computacionales inspirados en el cerebro humano, capaces de aprender patrones complejos a partir de grandes cantidades de datos. Su funcionamiento se asemeja al de las neuronas biológicas, conectándose y ajustando sus conexiones para mejorar su desempeño.

Las aplicaciones son vastas y van desde el reconocimiento de imágenes y voz, hasta la predicción de eventos futuros y la toma de decisiones complejas. Por ejemplo, las redes neuronales permiten a las computadoras entender y generar lenguaje humano, diagnosticar enfermedades, conducir vehículos autónomos y recomendar productos personalizados.

Básicamente, una red neuronal recibe datos de entrada, los procesa a través de múltiples capas y produce una salida. Si la salida no es la esperada, se ajusta la red para mejorar la próxima predicción. Este proceso de aprendizaje se repite muchas veces hasta que la red alcanza un alto nivel de precisión.


## Modelo ELMAN

El modelo ELMAN es un tipo específico de red neuronal recurrente (RNN), diseñada para procesar secuencias de datos. A diferencia de las redes neuronales feedforward tradicionales, que procesan cada dato de forma independiente, las RNN tienen conexiones recurrentes que les permiten "recordar" información de las entradas anteriores. Esto las hace ideales para tareas que involucran secuencias, como el procesamiento del lenguaje natural, el reconocimiento de voz y la predicción de series temporales.

En el caso de series de tiempo climáticas, como la temperatura superficial del mar (TSM), este modelo es particularmente adecuado. las series de tiempo climáticas suelen presentar patrones estacionales, tendencias a largo plazo y autocorrelaciones. El modelo ELMAN puede capturar estas dependencias gracias a su mecanismo de retroalimentación.


### Implementación del modelo

Como se abordó en capítulos anteriores, la serie de TSM analizada en este caso no presenta datos faltantes, incluye efectos de fenómenos climáticos como El Niño, que son ajenos a la estacionalidad de la señal, y se ha determinado que es estacionaria.sin embargo para facilitar la implementacion y analisis del modelo si fue necesario normalizar los datos. 

En el modelo implementado, se seleccionaron 20 rezagos como entrada para capturar suficiente contexto histórico de la serie temporal. Este número se eligió considerando que un mayor número de rezagos puede ayudar a modelar relaciones a largo plazo, aunque puede aumentar la complejidad computacional. Para la arquitectura de la red neuronal Elman, se definió un tamaño de red de 5 neuronas en la primera capa oculta y 2 en la segunda, buscando un equilibrio entre la capacidad de aprendizaje y la prevención de sobreajuste. La tasa de aprendizaje se estableció en 0.01, un valor relativamente bajo, con el objetivo de asegurar una convergencia estable durante el entrenamiento y evitar oscilaciones en la optimización. Además, se fijó un límite de 5000 iteraciones para garantizar que el modelo tuviera suficientes ciclos para ajustarse a los patrones de la serie temporal. La división de los datos se realizó utilizando un 80% para entrenamiento y el resto para prueba, siguiendo una práctica común que permite validar el desempeño del modelo sobre datos no vistos. Estos parámetros fueron seleccionados para maximizar la precisión del modelo al tiempo que se mantiene un buen desempeño general y se evitan problemas de sobreajuste o subajuste.

*  El RMSE (Root Mean Squared Error) representa la desviación promedio entre los valores reales y las predicciones del modelo, expresada en las mismas unidades que los datos. Un valor bajo indica que las predicciones están, en promedio, muy cerca de los valores reales, lo que refleja un buen ajuste del modelo.  

*  El MSE (Mean Squared Error) mide el promedio de los errores al cuadrado, lo que penaliza más fuertemente las desviaciones grandes. Es útil para diagnosticar cómo el modelo maneja los valores atípicos y se usa como base para calcular el RMSE. Sin embargo, por estar en unidades cuadradas, es menos intuitivo para interpretar directamente.

Los resultados obtenidos muestran un rendimiento aceptable del modelo Elman, con un RMSE de 0.072 y un MSE de 0.0052, lo que indica un error bajo en las predicciones normalizadas (0 a 1). En la gráfica de comparación, las predicciones (línea roja) siguen de cerca la tendencia general de los valores reales (línea azul), evidenciando que el modelo es capaz de capturar patrones generales de la serie temporal. Sin embargo, se observa un ligero desfase entre las predicciones y los valores reales, lo que podría indicar que el modelo no está ajustando adecuadamente la relación entre los rezagos y el valor objetivo. Además, en algunos picos y valles, el modelo presenta desviaciones en la magnitud, lo que sugiere limitaciones para captar variaciones locales rápidas o posibles ruidos en los datos. 


<button type="button" onclick="toggleCode('code1');">Mostrar Código</button>
<div id="code1" style="display:none;">

``` {r ELMAN, echo=TRUE, message=FALSE, warning=FALSE, eval=FALSE}

library(scales)
library(dplyr)
library(RSNNS)
library(Metrics)
library(plotly)

# Cargar datos
load("C:/Users/ASUS/OneDrive - PUJ Cali/2024_2/Series_de_tiempo/Unidad_1/bookdown-ST/df_tsm.RData")
#load("C:/Users/lvasquez/OneDrive - PUJ Cali/2024_2/Series_de_tiempo/Unidad_1/bookdown-ST/df_tsm.RData")

# Fijar la semilla para reproducibilidad
set.seed(123)

# Crear una copia del data frame original
df_tsm_ELMAN <- df_tsm

# Aplicamos la normalización min-max a la columna 'tsm'
df_tsm_ELMAN$tsm <- rescale(df_tsm_ELMAN$tsm, to = c(0, 1))

# Crear una matriz con 10 rezagos y los valores actuales
lag <- 20  # Número de rezagos
data_matrix <- embed(df_tsm_ELMAN$tsm, lag + 1)  # Incluye el objetivo y los rezagos

# Separar los valores actuales (objetivo) y los rezagos
outputs_ELMAN <- data_matrix[, 1]          # Primera columna: valores actuales (objetivo)
inputs_ELMAN <- data_matrix[, -1]         # Otras columnas: rezagos (características)

# Filtrar filas completas (sin NA)
inputs_ELMAN <- inputs_ELMAN[complete.cases(inputs_ELMAN), ]
outputs_ELMAN <- outputs_ELMAN[complete.cases(inputs_ELMAN)]

# Dividir los datos en entrenamiento y prueba 
train_size <- floor(0.8 * nrow(df_tsm_ELMAN))
train <- 1:train_size


# Entrenar la red Elman
fit_ELMAN <- elman(inputs_ELMAN[train, ],
                   outputs_ELMAN[train],
                   size = c(5, 2),
                   learnFuncParams = c(0.01),
                   maxit = 5000)

# Hacer predicciones
predictions_ELMAN <- predict(fit_ELMAN, inputs_ELMAN[-train, ])

# Evaluar el modelo (calcular metricas)
rmse <- rmse(predictions_ELMAN, outputs_ELMAN[-train])
mse_ELMAN <- mean((predictions_ELMAN - outputs_ELMAN[-train])^2)
#r_squared <- rSquared(predictions_ELMAN, outputs_ELMAN[-train])

print(paste("El RMSE calculado es:", rmse))
print(paste("El MSE calculado es:", mse_ELMAN))

# Crear un data frame con los datos reales y predicciones
results <- data.frame(
  Index = 1:length(outputs_ELMAN[-train]),
  Real = outputs_ELMAN[-train],
  Predicted = predictions_ELMAN
)

# Crear la gráfica interactiva
fig <- plot_ly(data = results) %>%
  add_lines(x = ~Index, y = ~Real, name = "Valores reales", line = list(color = 'blue')) %>%
  add_lines(x = ~Index, y = ~Predicted, name = "Predicciones", line = list(color = 'red'))

# Configurar el diseño con layout()
fig <- layout(fig,
  title = "Comparación de Valores Reales vs Predicciones",
  xaxis = list(title = "Índice"),
  yaxis = list(title = "Valores"),
  legend = list(x = 0.1, y = 0.9)
)

# Mostrar la gráfica
fig


```

</div> <script> function toggleCode(codeId) { var x = document.getElementById(codeId); if (x.style.display === "none") { x.style.display = "block"; } else { x.style.display = "none"; } } 
</script>


``` {r ELMAN1, message=FALSE, warning=FALSE, echo=FALSE, out.width="80%", fig.cap="*Pronóstico de TSM empleando la red neuronal de ELMAN*", fig.align='center'}

library(scales)
library(dplyr)
library(RSNNS)
library(Metrics)
library(plotly)

# Cargar datos
load("C:/Users/ASUS/OneDrive - PUJ Cali/2024_2/Series_de_tiempo/Unidad_1/bookdown-ST/df_tsm.RData")
#load("C:/Users/lvasquez/OneDrive - PUJ Cali/2024_2/Series_de_tiempo/Unidad_1/bookdown-ST/df_tsm.RData")

# Fijar la semilla para reproducibilidad
set.seed(123)

# Crear una copia del data frame original
df_tsm_ELMAN <- df_tsm

# Aplicamos la normalización min-max a la columna 'tsm'
df_tsm_ELMAN$tsm <- rescale(df_tsm_ELMAN$tsm, to = c(0, 1))

# Crear una matriz con 10 rezagos y los valores actuales
lag <- 20  # Número de rezagos
data_matrix <- embed(df_tsm_ELMAN$tsm, lag + 1)  # Incluye el objetivo y los rezagos

# Separar los valores actuales (objetivo) y los rezagos
outputs_ELMAN <- data_matrix[, 1]          # Primera columna: valores actuales (objetivo)
inputs_ELMAN <- data_matrix[, -1]         # Otras columnas: rezagos (características)

# Filtrar filas completas (sin NA)
inputs_ELMAN <- inputs_ELMAN[complete.cases(inputs_ELMAN), ]
outputs_ELMAN <- outputs_ELMAN[complete.cases(inputs_ELMAN)]

# Dividir los datos en entrenamiento y prueba 
train_size <- floor(0.8 * nrow(df_tsm_ELMAN))
train <- 1:train_size


# Entrenar la red Elman
fit_ELMAN <- elman(inputs_ELMAN[train, ],
                   outputs_ELMAN[train],
                   size = c(5, 2),
                   learnFuncParams = c(0.01),
                   maxit = 5000)

# Hacer predicciones
predictions_ELMAN <- predict(fit_ELMAN, inputs_ELMAN[-train, ])

# Evaluar el modelo (calcular metricas)
rmse <- rmse(predictions_ELMAN, outputs_ELMAN[-train])
mse_ELMAN <- mean((predictions_ELMAN - outputs_ELMAN[-train])^2)
#r_squared <- rSquared(predictions_ELMAN, outputs_ELMAN[-train])


print(paste("El RMSE calculado es:", rmse))
print(paste("El MSE calculado es:", mse_ELMAN))


# Crear un data frame con los datos reales y predicciones
results <- data.frame(
  Index = 1:length(outputs_ELMAN[-train]),
  Real = outputs_ELMAN[-train],
  Predicted = predictions_ELMAN
)

# Crear la gráfica interactiva
fig <- plot_ly(data = results) %>%
  add_lines(x = ~Index, y = ~Real, name = "Valores reales", line = list(color = 'blue')) %>%
  add_lines(x = ~Index, y = ~Predicted, name = "Predicciones", line = list(color = 'red'))

# Configurar el diseño con layout()
fig <- layout(fig,
  title = "Comparación de Valores Reales vs Predicciones",
  xaxis = list(title = "Índice"),
  yaxis = list(title = "Valores"),
  legend = list(x = 0.1, y = 0.9)
)

# Mostrar la gráfica
fig


```

## Modelo JORDAN

Un modelo Jordan es una arquitectura de red neuronal recurrente diseñada específicamente para el análisis de series temporales. Al aprovechar la información de los instantes de tiempo previos, este modelo es capaz de capturar patrones y dependencias temporales inherentes a los datos secuenciales. Su funcionamiento se basa en un mecanismo de retroalimentación interna que permite al modelo "recordar" información relevante del pasado, lo cual es fundamental para realizar predicciones precisas. Esta característica lo convierte en una herramienta adecuada para diversos campos, como la meteorología, la economía y la finanzas, donde la comprensión de la evolución temporal de los datos es un factor importante.

Los modelos Jordan demuestran una particular idoneidad para el análisis de series temporales climáticas, como la temperatura superficial del mar (TSM). Su capacidad para capturar patrones estacionales, tendencias a largo plazo y fluctuaciones aleatorias inherentes a estos fenómenos naturales, considerandose una herramienta de interés en el campo de la climatología. Al modelar la TSM, los modelos Jordan pueden identificar ciclos climáticos, eventos extremos como El Niño-Oscilación del Sur (ENOS) y predecir futuras variaciones en la temperatura. Sin embargo, es esencial considerar la complejidad de los sistemas climáticos y la disponibilidad de datos de alta calidad, para garantizar la precisión de los pronósticos.


### Implementación del modelo

asi como se mensiono en el modelo ELMAN la serie de TSM analizada en este caso no presenta datos faltantes, incluye efectos de fenómenos climáticos como El Niño, que son ajenos a la estacionalidad de la señal, y se ha determinado que es estacionaria.sin embargo para facilitar la implementacion y analisis del modelo si fue necesario normalizar los datos. 

En esta red neuronal de Jordan, se seleccionaron tres hiperparámetros clave para el entrenamiento del modelo: el número de neuronas en la capa oculta (size), la tasa de aprendizaje (learnFuncParams), y el número máximo de iteraciones (maxit). El número de neuronas en la capa oculta se fijó en 10, lo que permite que el modelo capture relaciones más complejas sin arriesgarse a ser excesivamente complejo y propenso al sobreajuste. La tasa de aprendizaje se estableció en 0.01, un valor moderado que ayuda a ajustar los pesos de la red de manera estable sin riesgo de oscilaciones o falta de convergencia. Finalmente, el número máximo de iteraciones se configuró en 5000, lo que ofrece al modelo suficiente tiempo para aprender de los datos y alcanzar una solución adecuada. Estos valores fueron seleccionados para lograr un equilibrio entre el rendimiento y la capacidad de generalización del modelo, basándose en la necesidad de capturar patrones temporales sin que el modelo se sobreajuste a los datos de entrenamiento.

Los resultados obtenidos demuestran un desempeño aceptable del modelo Jordan, con un RMSE de 0.076 y un MSE de 0.0057, lo que refleja un bajo nivel de error en las predicciones normalizadas (rango de 0 a 1). En la gráfica comparativa, las predicciones (línea roja) reproducen de manera consistente la tendencia general de los valores reales (línea azul), lo que evidencia la capacidad del modelo para capturar patrones globales de la serie temporal. Sin embargo, al igual que en el caso anterior, se observa un leve desfase entre las predicciones y los valores reales. Esto podría indicar que el modelo no está ajustando de manera óptima la relación entre los rezagos y el valor objetivo. Asimismo, en ciertos picos y valles, se identifican desviaciones en la magnitud de las predicciones, lo que sugiere limitaciones del modelo para capturar cambios locales rápidos o para manejar posibles ruidos presentes en los datos.


<button type="button" onclick="toggleCode('code2');">Mostrar Código</button>
<div id="code2" style="display:none;">

``` {r JORDAN, echo=TRUE, message=FALSE, warning=FALSE, eval=FALSE}

library(scales)
library(dplyr)
library(RSNNS)
library(Metrics)

# Fijar la semilla para reproducibilidad
set.seed(123)

# Crear una copia del data frame original
df_tsm_JORDAN <- df_tsm

# Aplicamos la normalización min-max a la columna 'tsm'
df_tsm_JORDAN$tsm <- rescale(df_tsm_JORDAN$tsm, to = c(0, 1))

# Crear una matriz con 10 rezagos y los valores actuales
lag <- 20  # Número de rezagos
data_matrix <- embed(df_tsm_JORDAN$tsm, lag + 1)  # Incluye el objetivo y los rezagos

# Separar los valores actuales (objetivo) y los rezagos
outputs_JORDAN <- data_matrix[, 1]          # Primera columna: valores actuales (objetivo)
inputs_JORDAN <- data_matrix[, -1]         # Otras columnas: rezagos (características)

# Filtrar filas completas (sin NA)
inputs_JORDAN <- inputs_JORDAN[complete.cases(inputs_JORDAN), ]
outputs_JORDAN <- outputs_JORDAN[complete.cases(inputs_JORDAN)]


# Dividir los datos en entrenamiento y prueba (ajusta según tu necesidad)
train_size <- floor(0.8 * nrow(df_tsm_JORDAN))
train <- 1:train_size


# Entrenar la red JORDAN
fit_Jordan<-jordan(inputs_JORDAN[train, ],
                   outputs_JORDAN[train],
                   size=10,
                   learnFuncParams=c(0.01),
                   maxit=5000)

# Hacer predicciones
predictions_Jordan <- predict(fit_Jordan, inputs_JORDAN[-train, ])

# Evaluar el modelo (calcular métricas)
rmse_Jordan <- rmse(predictions_Jordan, outputs_JORDAN[-train])
mse_Jordan <- mean((predictions_Jordan - outputs_JORDAN[-train])^2)
#r_squared_Jordan <- rSquared(predictions_Jordan, outputs_JORDAN[-train])

print(paste("El RMSE calculado es:", rmse_Jordan))
print(paste("El MSE calculado es:", mse_Jordan))


# Crear un data frame con los datos reales y predicciones
results <- data.frame(
  Index = 1:length(outputs_JORDAN[-train]),
  Real = outputs_JORDAN[-train],
  Predicted = predictions_Jordan
)

# Crear la gráfica interactiva
fig <- plot_ly(data = results) %>%
  add_lines(x = ~Index, y = ~Real, name = "Valores reales", line = list(color = 'blue')) %>%
  add_lines(x = ~Index, y = ~Predicted, name = "Predicciones", line = list(color = 'red'))

# Configurar el diseño con layout()
fig <- layout(fig,
  title = "Comparación de Valores Reales vs Predicciones",
  xaxis = list(title = "Índice"),
  yaxis = list(title = "Valores"),
  legend = list(x = 0.1, y = 0.9)
)

# Mostrar la gráfica
fig


```

</div> <script> function toggleCode(codeId) { var x = document.getElementById(codeId); if (x.style.display === "none") { x.style.display = "block"; } else { x.style.display = "none"; } } 
</script>


``` {r JORDAN1, message=FALSE, warning=FALSE, echo=FALSE, out.width="80%", fig.cap="*Pronóstico de TSM empleando la red neuronal de JORDAN*", fig.align='center'}

library(scales)
library(dplyr)
library(RSNNS)
library(Metrics)

# Fijar la semilla para reproducibilidad
set.seed(123)

# Crear una copia del data frame original
df_tsm_JORDAN <- df_tsm

# Aplicamos la normalización min-max a la columna 'tsm'
df_tsm_JORDAN$tsm <- rescale(df_tsm_JORDAN$tsm, to = c(0, 1))

# Crear una matriz con 10 rezagos y los valores actuales
lag <- 20  # Número de rezagos
data_matrix <- embed(df_tsm_JORDAN$tsm, lag + 1)  # Incluye el objetivo y los rezagos

# Separar los valores actuales (objetivo) y los rezagos
outputs_JORDAN <- data_matrix[, 1]          # Primera columna: valores actuales (objetivo)
inputs_JORDAN <- data_matrix[, -1]         # Otras columnas: rezagos (características)

# Filtrar filas completas (sin NA)
inputs_JORDAN <- inputs_JORDAN[complete.cases(inputs_JORDAN), ]
outputs_JORDAN <- outputs_JORDAN[complete.cases(inputs_JORDAN)]


# Dividir los datos en entrenamiento y prueba (ajusta según tu necesidad)
train_size <- floor(0.8 * nrow(df_tsm_JORDAN))
train <- 1:train_size


# Entrenar la red JORDAN
fit_Jordan<-jordan(inputs_JORDAN[train, ],
                   outputs_JORDAN[train],
                   size=10,
                   learnFuncParams=c(0.01),
                   maxit=5000)

# Hacer predicciones
predictions_Jordan <- predict(fit_Jordan, inputs_JORDAN[-train, ])

# Evaluar el modelo (calcular métricas)
rmse_Jordan <- rmse(predictions_Jordan, outputs_JORDAN[-train])
mse_Jordan <- mean((predictions_Jordan - outputs_JORDAN[-train])^2)
#r_squared_Jordan <- rSquared(predictions_Jordan, outputs_JORDAN[-train])

print(paste("El RMSE calculado es:", rmse_Jordan))
print(paste("El MSE calculado es:", mse_Jordan))


# Crear un data frame con los datos reales y predicciones
results <- data.frame(
  Index = 1:length(outputs_JORDAN[-train]),
  Real = outputs_JORDAN[-train],
  Predicted = predictions_Jordan
)

# Crear la gráfica interactiva
fig <- plot_ly(data = results) %>%
  add_lines(x = ~Index, y = ~Real, name = "Valores reales", line = list(color = 'blue')) %>%
  add_lines(x = ~Index, y = ~Predicted, name = "Predicciones", line = list(color = 'red'))

# Configurar el diseño con layout()
fig <- layout(fig,
  title = "Comparación de Valores Reales vs Predicciones",
  xaxis = list(title = "Índice"),
  yaxis = list(title = "Valores"),
  legend = list(x = 0.1, y = 0.9)
)

# Mostrar la gráfica
fig
```

## Análisis Comparativo de Modelos ELMAN y JORDAN

En comparación entre los modelos Elman y Jordan implementados, se observan diferencias en su comportamiento y desempeño. El modelo Elman mostró un RMSE de 0.072 y un MSE de 0.0052, mientras que el modelo Jordan presentó un RMSE de 0.076 y un MSE de 0.0057. Aunque ambos modelos tienen un rendimiento aceptable con errores bajos en las predicciones normalizadas, el modelo Elman presentó un mejor ajuste, reflejado en los valores más bajos de RMSE y MSE. En términos de patrones, ambos modelos lograron capturar la tendencia general de la serie temporal, con predicciones cercanas a los datos reales. Sin embargo, en ambos casos se observaron desfases y desviaciones en los picos y valles, lo que indica limitaciones para captar variaciones locales rápidas y posibles ruidos. A pesar de ello, el modelo Elman parece tener una ligera ventaja en precisión y ajuste debido a sus mejores métricas de error. Esto se podría atribuir a la arquitectura y configuración específica del modelo Elman, que, con un enfoque en la memoria temporal y una estructura ajustada, fue más efectivo para capturar patrones a largo plazo en comparación con el modelo Jordan. En conclusión, el modelo Elman es ligeramente superior en términos de ajuste y precisión, pero ambos presentan limitaciones similares que podrían abordarse mediante ajustes en sus hiperparámetros o arquitecturas.

## ¿Por qué ELMAN podría ser mejor en este caso?

Existen varias razones que podrían explicar por qué el modelo Elman superó al modelo Jordan en este caso particular. En primer lugar, las diferencias en la arquitectura de ambas redes neuronales pueden haber influido en su capacidad para modelar la serie de tiempo. Además, la elección de los hiperparámetros, como el número de neuronas en las capas ocultas y la tasa de aprendizaje, podría haber sido más adecuada para el modelo Elman, permitiéndole ajustarse mejor a los patrones de los datos. Por otro lado, la naturaleza específica de la serie de tiempo, que puede incluir características como estacionalidad, tendencia y ruido, también podría haber favorecido el desempeño del modelo Elman en comparación con el modelo Jordan. Estas diferencias en arquitectura, configuración y en las propiedades de los datos son factores clave que explican el mejor desempeño del modelo Elman en este análisis.
